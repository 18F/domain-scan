#!/usr/bin/env python

import os
import utils
import logging
import csv
import json

# basic setup - logs, output dirs
options = utils.options()
utils.configure_logging(options)
utils.mkdir_p("cache")
utils.mkdir_p("results")

# make site-inspector path overrideable
site_inspector_cmd = os.environ.get("SITE_INSPECTOR_PATH", "site-inspector")


def domains_from(arg):
    if arg.endswith(".csv"):
        with open(arg, newline='') as csvfile:
            for row in csv.reader(csvfile):
                if (not row[0]) or (row[0].lower().startswith("domain")):
                    continue
                yield row[0].lower(), row[1:]
    else:
        yield arg, []


# run a method over every domain, write row to output file
def scan_domains(scanner, domains, output):
    with open(output, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(scanner.headers)

        for domain, other in domains_from(domains):
            for row in scanner(domain, other):
                if row:
                    writer.writerow(row)

    logging.warn("Results written to %s" % output)


def dependencies():
    return


# marker for a cached invalid response
def invalid():
    return utils.json_for({'invalid': True})


def run(options=None):

    if not options["_"]:
        logging.error("Provide a CSV file, or domain name.")
        exit()

    if not utils.try_command(site_inspector_cmd):
        logging.error("You need `site-inspector` to scan site details.")
        exit()
    scan_domains(inspect, options["_"][0], 'results/inspect.csv')

    if options.get("tls"):
        if not utils.try_command("ssllabs-scan"):
            logging.error("You need `ssllabs-scan` to scan TLS details.")
            exit()
        scan_domains(tls, 'results/inspect.csv', 'results/tls.csv')


##
# Inspect a domain's fundamentals using site-inspector.
##
def inspect(domain, other=None):

    logging.debug("[%s][inspect]" % domain)

    # cache JSON as it comes back from site-inspector
    cache = cache_path(domain, "inspect")
    if (options.get("force", False) is False) and (os.path.exists(cache)):
        logging.debug("\tCached.")
        raw = open(cache).read()
        data = json.loads(raw)
        if data.get('invalid'):
            return None

    else:
        logging.debug("\t %s %s --http" % (site_inspector_cmd, domain))
        raw = utils.scan([site_inspector_cmd, domain, "--http"])
        if not raw:
            utils.write(invalid(), cache)
            return None
        utils.write(raw, cache)
        data = json.loads(raw)

    # always returns 1 row

    canonical_https = data['endpoints']['https'][data['canonical_endpoint']]
    https_valid = canonical_https.get('https_valid', False)
    https_bad_chain = canonical_https.get('https_bad_chain', False)
    https_bad_name = canonical_https.get('https_bad_name', False)

    yield [
        domain, data['canonical'], data['up'],
        data['redirect'], data['redirect_to'],
        https_valid, data['default_https'], data['downgrade_https'],
        data['enforce_https'],
        https_bad_chain, https_bad_name,
        data['hsts'], data['hsts_header'], data['hsts_entire_domain'],
        data['hsts_entire_domain_preload'],
        data['broken_root'], data['broken_www']
    ]

inspect.headers = [
    "Domain", "Canonical", "Live",
    "Redirect", "Redirect To",
    "Valid HTTPS", "Defaults to HTTPS",
    "Downgrades HTTPS", "Strictly Forces HTTPS",
    "HTTPS Bad Chain", "HTTPS Bad Hostname",
    "HSTS", "HSTS Header", "HSTS All Subdomains", "HSTS Preload Ready",
    "Broken Root", "Broken WWW"
]


###
# Inspect a site's valid TLS configuration using ssllabs-scan.
#
# Requires `other` to have fields from an inspect CSV.
# Only processes live domains with valid HTTPS.
###
def tls(domain, other=None):
    logging.debug("[%s][tls]" % domain)

    # other[1] = Live, other[4] = Valid HTTPS, other[8] = HTTPS Bad Chain
    if other and (not ((other[1] == 'True') and
                  ((other[4] == 'True') or (other[8] == 'True')))):
        logging.debug("\tSkipping.")
        yield None

    else:
        # cache reformatted JSON from ssllabs
        cache = cache_path(domain, "tls")

        force = options.get("force", False)

        if (force is False) and (os.path.exists(cache)):
            logging.debug("\tCached.")
            raw = open(cache).read()
            data = json.loads(raw)
        else:
            logging.debug("\t ssllabs-scan %s" % domain)

            usecache = str(not force).lower()

            if options.get("debug"):
                cmd = ["ssllabs-scan", "--usecache=%s" % usecache,
                       "--verbosity=debug", domain]
            else:
                cmd = ["ssllabs-scan", "--usecache=%s" % usecache,
                       "--quiet", domain]
            raw = utils.scan(cmd)
            if raw:
                data = json.loads(raw)
                # we only give ssllabs-scan one at a time,
                # so we can de-pluralize this
                data = data[0]
                utils.write(utils.json_for(data), cache)
            else:
                return None
                # raise Exception("Invalid data from ssllabs-scan: %s" % raw)

        # can return multiple rows, one for each 'endpoint'
        for endpoint in data['endpoints']:

            # this meant it couldn't connect to the endpoint
            if not endpoint.get("grade"):
                continue

            sslv3 = False
            tlsv12 = False
            for protocol in endpoint['details']['protocols']:
                if ((protocol['name'] == "SSL") and
                        (protocol['version'] == '3.0')):
                    sslv3 = True
                if ((protocol['name'] == "TLS") and
                        (protocol['version'] == '1.2')):
                    tlsv12 = True

            spdy = False
            h2 = False
            npn = endpoint['details'].get('npnProtocols', None)
            if npn:
                spdy = ("spdy" in npn)
                h2 = ("h2-" in npn)

            yield [
                domain, endpoint['grade'],
                endpoint['details']['cert']['sigAlg'],
                endpoint['details']['key']['alg'],
                endpoint['details']['key']['size'],
                endpoint['details']['forwardSecrecy'],
                endpoint['details']['ocspStapling'],
                endpoint['details']['heartbleed'],
                sslv3,
                endpoint['details']['key'].get('debianFlaw', False),
                tlsv12,
                spdy,
                endpoint['details']['sniRequired'],
                h2
            ]

tls.headers = [
    "Domain", "Grade",
    "Signature Algorithm", "Key Type", "Key Size",  # strength
    "Forward Secrecy", "OCSP Stapling",  # privacy
    "Heartbleed", "SSLv3", "Debian Flaw",  # bad things
    "TLSv1.2", "SPDY", "Requires SNI",  # forward
    "HTTP/2",  # ever forward
]


###
# Run a mixed content scan on the domain.
#
# Requires `other` to be details from an inspect CSV.
# Only processes live domains. If HTTPS is enabled and forced,
# then uses the `https://` version of the domain
###
def mixed(domain, other=None):
    logging.debug("[%s][mixed]" % domain)

    # other[1] = Live
    if other and (not (other[1] == 'True')):
        logging.debug("\tSkipping.")
        yield None

    else:
        # cache restructured data from mixed-content-scam

        cache = cache_path(domain, "mixed")
        if (os.path.exists(cache)):
            logging.debug("\tCached.")
            raw = open(cache).read()
        else:
            # Only use HTTPS if it's forced. Otherwise, assume the domain
            # still needs to evaluate what mixed content appears on the
            # HTTP version.
            #
            # Use the canonical domain, as calculated by site-inspector,
            # to pick what URL to scan.
            #
            # other[0] = Canonical, other[4] = HTTPS,
            # other[5] = Defaults to HTTPS?
            effective = other[0]
            if (other[3] == "True") and (other[4] == "True"):
                effective = "https://%s" % effective
            else:
                effective = "http://%s" % effective

            logging.debug("\t mixed-content-scan --format=json %s" % effective)

            cmd = ["mixed-content-scan", "--format=json", effective]
            raw = utils.scan(cmd)
            if raw:
                # read line by line, store two dicts - by page, by resource

                # data = json.loads(raw)
                utils.write(raw, cache)
            else:
                return None
                # raise Exception("Invalid data from ssllabs-scan: %s" % raw)


mixed.headers = [
    "Domain", "Pages", "Resources"
]


def cache_path(domain, operation):
    return os.path.join(utils.data_dir(), operation, ("%s.json" % domain))


if __name__ == '__main__':
    run(options)
