#!/usr/bin/env python3

import multiprocessing
import os
import uuid
import sys
import glob
import datetime
import logging
import requests
import importlib
import shutil
import csv
import json
import base64
import boto3
import botocore
from concurrent.futures import ThreadPoolExecutor

from scanners import utils

# basic setup - logs, output dirs
options = utils.options()
domain_suffix = options.get("suffix")
utils.configure_logging(options)
utils.mkdir_p(utils.cache_dir())
utils.mkdir_p(utils.results_dir())

# Default amount of local workers (threads) per-scanner.
default_workers = 10

lambda_client = None

# some metadata about the scan itself
start_time = utils.utc_timestamp()
start_command = str.join(" ", sys.argv)

# Fields that always get prefixed before scan-specific data.
prefix_headers = ["Domain", "Base Domain", "Scan Errors"]

###
# Entry point. `options` is a dict of CLI flags.
###


def run(options=None):

    if not options["_"]:
        logging.error("Provide a CSV file, or domain name.")
        exit(1)

    if not options.get("scan"):
        logging.error("--scan must be one or more scanners.")
        exit(1)

    # `domains` can be either a path or a domain name.
    # It can also be a URL, and if it is we want to download it now,
    # and then adjust the value to be the path of the cached download.
    domains = options["_"][0]

    if domains.startswith("http:") or domains.startswith("https:"):

        domains_path = os.path.join(utils.cache_dir(), "domains.csv")

        try:
            response = requests.get(domains)
            utils.write(response.text, domains_path)
        except:
            logging.error("Domains URL not downloaded successfully.")
            print(utils.format_last_exception())
            exit(1)

        domains = domains_path

    # Which scanners to run the domain through.
    scans = []

    for name in options.get("scan").split(","):
        try:
            scanner = importlib.import_module("scanners.%s" % name)
        except ImportError:
            exc_type, exc_value, exc_traceback = sys.exc_info()
            logging.error("[%s] Scanner not found, or had an error during loading.\n\tERROR: %s\n\t%s" % (name, exc_type, exc_value))
            exit(1)

        # If the scanner has a canonical command, make sure it exists.
        if hasattr(scanner, "command") and scanner.command and (not utils.try_command(scanner.command)):
            logging.error("[%s] Command not found: %s" %
                          (name, scanner.command))
            exit(1)

        # Scanners can have an optional init/validation hook.
        if hasattr(scanner, "init") and scanner.init and (not scanner.init(options)):
            logging.error("[%s] Scanner's init hook returned false." % name)
            exit(1)

        scans.append(scanner)

    scan_domains(scans, domains)


###
# Given the selected scanners, and input domains, run each domain
# through each scanner.
#
# Produces a CSV for each scan, with each domain and results.
###
def scan_domains(scanners, domains):
    # Clear out existing result CSVs, to avoid inconsistent data.
    for result in glob.glob("%s/*.csv" % utils.results_dir()):
        os.remove(result)

    # Run through each scanner and open a file and CSV for each.
    handles = {}
    for scanner in scanners:
        name = scanner.__name__.split(".")[-1]  # e.g. 'pshtt'
        scanner_filename = "%s/%s.csv" % (utils.results_dir(), name)
        scanner_file = open(scanner_filename, 'w', newline='')
        scanner_writer = csv.writer(scanner_file)
        scanner_writer.writerow(prefix_headers + scanner.headers)

        handles[scanner] = {
            'name': name,
            'file': scanner_file,
            'filename': scanner_filename,
            'writer': scanner_writer
        }

    # Experimental!
    if options.get("lambda", False):
        scan_method = perform_lambda_scan
    else:
        scan_method = perform_local_scan

    extras = {}

    # Generate a random UUID for the entire scan.
    extras['uuid'] = str(uuid.uuid4())
    logging.warn("[%s] Scan UUID." % extras['uuid'])

    # Run each scanner (unique process pool) over each domain.
    # User can force --serial, and scanners can override default of 10.
    for scanner in scanners:

        if options.get("serial"):
            workers = 1
        elif hasattr(scanner, "workers"):
            workers = scanner.workers
        else:
            workers = int(options.get("workers", default_workers))

        # Accept initiating a new client per-scanner, so that scanner-
        # specific worker defaults can be accounted for in the pool.
        # Requires AWS credentials to have been established elsewhere.
        config = botocore.config.Config(max_pool_connections=workers)
        extras['lambda_client'] = boto3.client('lambda', config=config)

        with ThreadPoolExecutor(max_workers=workers) as executor:
            tasks = ((scanner, domain, handles, extras, options) for domain in domains_from(domains))
            executor.map(scan_method, tasks)

    # Close up all the files, --sort if requested (expensive).
    for scanner in scanners:
        handles[scanner]['file'].close()
        if options.get("sort"):
            utils.sort_csv(handles[scanner]['filename'])

    logging.warn("Results written to CSV.")

    # Save metadata.
    metadata = {
        'start_time': start_time,
        'end_time': utils.utc_timestamp(),
        'command': start_command
    }
    utils.write(utils.json_for(metadata), "%s/meta.json" % utils.results_dir())


###
# Local scan (default).
def perform_local_scan(params):
    scanner, domain, handles, extras, options = params

    errors = []

    # A scanner can return multiple rows.
    try:
        # This pulls this perticular scan's data all into memory.
        logging.warn("[%s][%s] Running locally..." % (domain, handles[scanner]['name']))
        rows = list(scanner.scan(domain, options))
    except:
        exception = utils.format_last_exception()
        errors.append("Unknown exception: %s" % exception)
        logging.warn(exception)

    write_rows(rows, domain, errors, scanner, handles[scanner]['writer'])


###
# Lambda-based scan. (Experimental!)
def perform_lambda_scan(params):
    scanner, domain, handles, extras, options = params

    errors = []
    rows = None

    # Most of the function in the try block because it's otherwise
    # not easy to do error handling on a worker thread.
    try:
        # For now, do synchronous Lambda requests, essentially just
        # farming out the hard work to Lambda. This increases max workers
        # somewhat, since waiting on responses is much, much cheaper than
        # performing active scanning.
        task_prefix = "task_" # default, maybe make optional later
        task_name = "%s%s" % (task_prefix, handles[scanner]['name'])

        # JSON payload that arrives as the 'event' object in Lambda.
        payload = {'domain': domain, 'options': options}
        bytes_payload = bytes(utils.json_for(payload), encoding='utf-8')

        # Send up scan UUID to make log filtering easier.
        context = {
            'custom': {'scan_uuid': extras['uuid']}
        }
        bytes_context = bytes(utils.json_for(context), encoding='utf-8')
        encoded_context = str(base64.b64encode(bytes_context), encoding='utf-8')

        # Lambda client initialized during scan initialization, per-scanner.
        lambda_client = extras['lambda_client']

        # Assumes Lambda task has already been created and set.
        logging.warn("[%s][%s] Running Lambda function..." % (domain, task_name))
        # logging.debug("\tInvoking Lambda function %s with payload:\n%s" % (task_name, payload))

        api_response = lambda_client.invoke(
            FunctionName=task_name,
            InvocationType='RequestResponse',
            LogType='None',
            ClientContext=encoded_context,
            Payload=bytes_payload
        )

        raw = str(api_response['Payload'].read(), encoding='utf-8')
        response = json.loads(raw)

        if (type(response) is dict):
            # TODO: Lambda error message output helper function
            # TODO: Lambda-specific errors
            if response.get("errorMessage") is not None:
                logging.warn("[%s][%s] Lambda error! \n\t%s" % (domain, task_name, raw))
                errors.append("Lambda error: %s" % raw)
            else:
                logging.warn("[%s][%s] Unknown response type! \n\t%s" % (domain, task_name, raw))
                errors.append("Unknown response from Lambda: %s" % raw)
        else: # type(response) is list:
            # logging.debug(response)
            rows = response

    except botocore.vendored.requests.exceptions.ReadTimeout:
        errors.append("Connection timeout while talking to Lambda.")
    except:
        exception = utils.format_last_exception()
        errors.append("Unknown exception: %s" % exception)
        logging.warn(exception)

    # Wrap this separately to capture previously caught errors,
    # but need to re-wrap it to catch arbitrary exceptions.
    try:
        write_rows(rows, domain, errors, scanner, handles[scanner]['writer'])
    except:
        logging.warn(utils.format_last_exception())


def write_rows(rows, domain, errors, scanner, csv_writer):
    standard_prefix = [
        domain,
        utils.base_domain_for(domain),
        " ".join(errors)
    ]

    # If we didn't get any info, we'll still output information about why the scan failed.
    if rows is None:
        empty_row = [None] * len(scanner.headers)
        rows = [empty_row]

    for row in rows:
        csv_writer.writerow(standard_prefix + row)

# Yield domain names from a single string, or a CSV of them.
def domains_from(arg):
    if arg.endswith(".csv"):
        with open(arg, encoding='utf-8', newline='') as csvfile:
            for row in csv.reader(csvfile):
                if (not row[0]) or (row[0].lower().startswith("domain")):
                    continue
                domain = row[0].lower()
                if domain_suffix:
                    yield "%s.%s" % (domain, domain_suffix)
                else:
                    yield domain
    else:
        yield arg


if __name__ == '__main__':

    # Makes it safer for multi-threaded executions of domain-scan
    # to make use of the multiprocessing module without causing
    # deadlocks.
    multiprocessing.set_start_method('forkserver')

    run(options)
