#!/usr/bin/env python

import sys, os
import utils
import logging
import csv, json

# basic setup - logs, output dirs
options = utils.options()
utils.configure_logging(options)
utils.mkdir_p("cache")
utils.mkdir_p("results")


def domains_from(arg):
  if arg.endswith(".csv"):
    with open(arg, newline='') as csvfile:
      for row in csv.reader(csvfile):
        if (not row[0]) or (row[0].lower().startswith("domain")):
          continue
        yield row[0].lower(), row[1:]
  else:
    yield arg, []

# run a method over every domain, write row to output file
def scan_domains(scanner, domains, output):
  with open(output, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(scanner.headers)

    for domain, other in domains_from(domains):
      for row in scanner(domain, other):
        if row:
          writer.writerow(row)

  logging.warn("Results written to %s" % output)

def dependencies():
  return

# marker for a cached invalid response
def invalid():
  return utils.json_for({'invalid': True})

def run(options=None):

  if not options["_"]:
    logging.error("Provide a CSV file, or domain name.")
    exit()

  if not utils.try_command("site-inspector"):
    logging.error("You need `site-inspector` to scan site details.")
    exit()
  scan_domains(inspect, options["_"][0], 'results/inspect.csv')

  if options.get("tls"):
    if not utils.try_command("ssllabs-scan"):
      logging.error("You need `ssllabs-scan` to scan TLS details.")
      exit()
    scan_domains(tls, 'results/inspect.csv', 'results/tls.csv')

##
# Inspect a domain's fundamentals using site-inspector.
##
def inspect(domain, other=None):

  logging.debug("[%s][inspect]" % domain)

  # cache JSON as it comes back from site-inspector
  cache = cache_path(domain, "inspect")
  if (options.get("force", False) == False) and (os.path.exists(cache)):
    logging.debug("\tCached.")
    raw = open(cache).read()
    data = json.loads(raw)
    if data.get('invalid'):
      return None

  else:
    logging.debug("\t site-inspector %s --http" % domain)
    raw = utils.scan(["site-inspector", domain, "--http"])
    if not raw:
      utils.write(invalid(), cache)
      return None
    utils.write(raw, cache)
    data = json.loads(raw)


  # always returns 1 row

  canonical_https = data['endpoints']['https'][data['canonical_endpoint']]
  https_valid = canonical_https.get('https_valid', False)
  https_bad_chain = canonical_https.get('https_bad_chain', False)
  https_bad_name = canonical_https.get('https_bad_name', False)


  yield [
    domain, data['canonical'], data['live'], data['redirect'],
    https_valid, data['enforce_https'], https_bad_chain, https_bad_name,
    data['hsts'], data['hsts_header'], data['hsts_entire_domain'], data['hsts_entire_domain_preload']

  ]

inspect.headers = [
  "Domain", "Canonical", "Live", "Redirect",
  "HTTPS?", "Force HTTPS", "HTTPS Bad Chain", "HTTPS Bad Hostname",
  "HSTS", "HSTS Header", "HSTS All Subdomains" "HSTS Preload"
]


###
# Inspect a site's valid TLS configuration using ssllabs-scan.
#
# Requires `other` to have fields from an inspect CSV.
# Only processes live domains with valid HTTPS.
###
def tls(domain, other=None):
  logging.debug("[%s][tls]" % domain)

  # other[1] = Live?, other[3] = HTTPS?
  if other and (not ((other[1] == 'True') and (other[3] == 'True'))):
    logging.debug("\tSkipping.")
    yield None

  else:
    # cache reformatted JSON from ssllabs
    cache = cache_path(domain, "tls")
    if (os.path.exists(cache)):
      logging.debug("\tCached.")
      raw = open(cache).read()
      data = json.loads(raw)
    else:
      logging.debug("\t ssllabs-scan %s" % domain)

      if options.get("debug"):
        cmd = ["ssllabs-scan", "--usecache=true", "--verbosity=debug", domain]
      else:
        cmd = ["ssllabs-scan", "--usecache=true", "--quiet", domain]
      raw = utils.scan(cmd)
      if raw:
        data = json.loads(raw)
        # we only give ssllabs-scan one at a time, so we can de-pluralize this
        data = data[0]
        utils.write(utils.json_for(data), cache)
      else:
        return None
        # raise Exception("Invalid data from ssllabs-scan: %s" % raw)

    # can return multiple rows, one for each 'endpoint'
    for endpoint in data['endpoints']:

      # this meant it couldn't connect to the endpoint
      if not endpoint.get("grade"):
        continue

      sslv3 = False
      tlsv12 = False
      for protocol in endpoint['details']['protocols']:
        if (protocol['name'] == "SSL") and (protocol['version'] == '3.0'):
          sslv3 = True
        if (protocol['name'] == "TLS") and (protocol['version'] == '1.2'):
          tlsv12 = True

      spdy = False
      h2 = False
      npn = endpoint['details'].get('npnProtocols', None)
      if npn:
        spdy = ("spdy" in npn)
        h2 = ("h2-" in npn)

      yield [
        domain, endpoint['grade'],
        endpoint['details']['cert']['sigAlg'],
        endpoint['details']['key']['alg'],
        endpoint['details']['key']['size'],
        endpoint['details']['forwardSecrecy'],
        endpoint['details']['ocspStapling'],
        endpoint['details']['heartbleed'],
        sslv3,
        endpoint['details']['key'].get('debianFlaw', False),
        tlsv12,
        spdy,
        endpoint['details']['sniRequired'],
        h2
      ]

tls.headers = [
  "Domain", "Grade",
  "Signature Algorithm", "Key Type", "Key Size", # strength
  "Forward Secrecy", "OCSP Stapling", # privacy
  "Heartbleed", "SSLv3", "Debian Flaw", # bad things
  "TLSv1.2", "SPDY", "Requires SNI", # forward
  "HTTP/2", # ever forward
  # "Server", "Hostname" # these belong at the site-inspector level
]

###
# Run a mixed content scan on the domain.
#
# Requires `other` to be details from an inspect CSV.
# Only processes live domains. If HTTPS is enabled and forced,
# then uses the `https://` version of the domain
###
def mixed(domain, other=None):
  logging.debug("[%s][mixed]" % domain)

  # other[1] = Live?
  if other and (not (other[1] == 'True')):
    logging.debug("\tSkipping.")
    yield None


  else:
    # cache restructured data from mixed-content-scam

    cache = cache_path(domain, "mixed")
    if (os.path.exists(cache)):
      logging.debug("\tCached.")
      raw = open(cache).read()
      data = json.loads(raw)

    else:
      # Only use HTTPS if it's forced. Otherwise, assume the domain
      # still needs to evaluate what mixed content appears on the
      # HTTP version.
      #
      # Use the canonical domain, as calculated by site-inspector,
      # to pick what URL to scan.
      #
      # other[0] = Canonical, other[3] = HTTPS?, other[4] = Force HTTPS?
      effective = other[0]
      if (other[3] == "True") and (other[4] == "True"):
        effective = "https://%s" % effective
      else:
        effective = "http://%s" % effective

      logging.debug("\t mixed-content-scan --format=json %s" % effective)

      cmd = ["mixed-content-scan", "--format=json", effective]
      raw = utils.scan(cmd)
      if raw:
        # read line by line, store two dicts - by page, by resource

        # data = json.loads(raw)
        utils.write(raw, cache)
      else:
        return None
        # raise Exception("Invalid data from ssllabs-scan: %s" % raw)


mixed.headers = [
  "Domain", "Pages", "Resources"
]

def cache_path(domain, operation):
  return os.path.join(utils.data_dir(), operation, ("%s.json" % domain))

run(options)
