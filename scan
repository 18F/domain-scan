#!/usr/bin/env python3

import os
import sys
import glob
import datetime
import logging
import requests
import importlib
import shutil
import csv
import json
import boto3
from concurrent.futures import ThreadPoolExecutor

from scanners import utils

# basic setup - logs, output dirs
options = utils.options()
domain_suffix = options.get("suffix")
utils.configure_logging(options)
utils.mkdir_p(utils.cache_dir())
utils.mkdir_p(utils.results_dir())

# Requires AWS credentials to have been established elsewhere.
client = boto3.client('lambda')

# some metadata about the scan itself
start_time = utils.utc_timestamp()
start_command = str.join(" ", sys.argv)

###
# Entry point. `options` is a dict of CLI flags.
###


def run(options=None):

    if not options["_"]:
        logging.error("Provide a CSV file, or domain name.")
        exit(1)

    if not options.get("scan"):
        logging.error("--scan must be one or more scanners.")
        exit(1)

    # `domains` can be either a path or a domain name.
    # It can also be a URL, and if it is we want to download it now,
    # and then adjust the value to be the path of the cached download.
    domains = options["_"][0]

    if domains.startswith("http:") or domains.startswith("https:"):

        domains_path = os.path.join(utils.cache_dir(), "domains.csv")

        try:
            response = requests.get(domains)
            utils.write(response.text, domains_path)
        except:
            logging.error("Domains URL not downloaded successfully.")
            print(utils.format_last_exception())
            exit(1)

        domains = domains_path

    # Which scanners to run the domain through.
    scans = []

    for name in options.get("scan").split(","):
        try:
            scanner = importlib.import_module("scanners.%s" % name)
        except ImportError:
            exc_type, exc_value, exc_traceback = sys.exc_info()
            logging.error("[%s] Scanner not found, or had an error during loading.\n\tERROR: %s\n\t%s" % (name, exc_type, exc_value))
            exit(1)

        # If the scanner has a canonical command, make sure it exists.
        if hasattr(scanner, "command") and scanner.command and (not utils.try_command(scanner.command)):
            logging.error("[%s] Command not found: %s" %
                          (name, scanner.command))
            exit(1)

        # Scanners can have an optional init/validation hook.
        if hasattr(scanner, "init") and scanner.init and (not scanner.init(options)):
            logging.error("[%s] Scanner's init hook returned false." % name)
            exit(1)

        scans.append(scanner)

    scan_domains(scans, domains)


###
# Given the selected scanners, and input domains, run each domain
# through each scanner.
#
# Produces a CSV for each scan, with each domain and results.
###
def scan_domains(scanners, domains):

    # Clear out existing result CSVs, to avoid inconsistent data.
    for result in glob.glob("%s/*.csv" % utils.results_dir()):
        os.remove(result)

    # Run through each scanner and open a file and CSV for each.
    handles = {}
    for scanner in scanners:
        name = scanner.__name__.split(".")[-1]  # e.g. 'pshtt'
        scanner_filename = "%s/%s.csv" % (utils.results_dir(), name)
        scanner_file = open(scanner_filename, 'w', newline='')
        scanner_writer = csv.writer(scanner_file)
        scanner_writer.writerow(["Domain", "Base Domain"] + scanner.headers)

        handles[scanner] = {
            'name': name,
            'file': scanner_file,
            'filename': scanner_filename,
            'writer': scanner_writer
        }

    # Experimental!
    if options.get("lambda", False):
        scan_method = perform_lambda_scan
    else:
        scan_method = perform_local_scan

    # Run each scanner (unique process pool) over each domain.
    # User can force --serial, and scanners can override default of 10.
    for scanner in scanners:

        if options.get("serial"):
            workers = 1
        elif hasattr(scanner, "workers"):
            workers = scanner.workers
        else:
            workers = int(options.get("workers", 10))

        with ThreadPoolExecutor(max_workers=workers) as executor:
            tasks = ((scanner, domain, handles, options) for domain in domains_from(domains))
            executor.map(scan_method, tasks)

    # Close up all the files, --sort if requested (expensive).
    for scanner in scanners:
        handles[scanner]['file'].close()
        if options.get("sort"):
            utils.sort_csv(handles[scanner]['filename'])

    logging.warn("Results written to CSV.")

    # Save metadata.
    metadata = {
        'start_time': start_time,
        'end_time': utils.utc_timestamp(),
        'command': start_command
    }
    utils.write(utils.json_for(metadata), "%s/meta.json" % utils.results_dir())


###
# Local scan (default).
def perform_local_scan(params):
    scanner, domain, handles, options = params

    # A scanner can return multiple rows.
    try:
        # This pulls this perticular scan's data all into memory.
        rows = list(scanner.scan(domain, options))
    except:
        logging.warn(utils.format_last_exception())

    # TODO function: write_rows(rows, domain, handles[scanner])
    if rows:
        for row in rows:
            if row:
                handles[scanner]['writer'].writerow([domain, utils.base_domain_for(domain)] + row)


###
# Lambda-based scan. (Experimental!)
def perform_lambda_scan(params):
    scanner, domain, handles, options = params

    # For now, do synchronous Lambda requests, essentially just
    # farming out the hard work to Lambda. This increases max workers
    # somewhat, since waiting on responses is much, much cheaper than
    # performing active scanning.
    task_prefix = "task_" # default, maybe make optional later
    task_name = "%s%s" % (task_prefix, handles[scanner]['name'])

    # JSON payload that arrives as the 'event' object in Lambda.
    payload = {'domain': domain, 'options': options}

    # Assumes Lambda task has already been created and set.
    try:
        logging.warn("\tInvoking Lambda function %s with payload:\n%s" % (task_name, payload))
        api_response = client.invoke(
            FunctionName=task_name,
            InvocationType='RequestResponse',
            LogType='None',
            # ClientContext='string', # may be useful for passing pshtt data
            Payload=bytes(utils.json_for(payload), encoding='utf-8')
        )

        # raw response is a string of a string
        raw = api_response['Payload'].read()
        less_raw = json.loads(raw)
        rows = json.loads(less_raw)
    except:
        logging.warn(utils.format_last_exception())

    # TODO function: write_rows(rows, domain, handles[scanner])
    if rows:
        for row in rows:
            if row:
                handles[scanner]['writer'].writerow([domain, utils.base_domain_for(domain)] + row)




# Yield domain names from a single string, or a CSV of them.
def domains_from(arg):
    if arg.endswith(".csv"):
        with open(arg, encoding='utf-8', newline='') as csvfile:
            for row in csv.reader(csvfile):
                if (not row[0]) or (row[0].lower().startswith("domain")):
                    continue
                domain = row[0].lower()
                if domain_suffix:
                    yield "%s.%s" % (domain, domain_suffix)
                else:
                    yield domain
    else:
        yield arg


if __name__ == '__main__':
    run(options)
